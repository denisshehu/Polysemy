{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from models.point_cloud import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:02:10.751260300Z",
     "start_time": "2023-12-11T19:02:09.115363500Z"
    }
   },
   "id": "3b4fba935096164d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "k = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:02:10.771365700Z",
     "start_time": "2023-12-11T19:02:10.758931700Z"
    }
   },
   "id": "d403c169bb548ea3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "embeddings_paths = [word2vec_embeddings_path, fasttext_embeddings_path, glove_embeddings_path]\n",
    "filename_prefixes = ['word2vec', 'fasttext', 'glove']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:02:10.796401500Z",
     "start_time": "2023-12-11T19:02:10.770352100Z"
    }
   },
   "id": "e44fdc735c00c826"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mits_d\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mDesktop\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfilename_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfiltered\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mfilter_word_embeddings\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m      5\u001B[0m     file\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mload_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m embeddings\u001B[38;5;241m.\u001B[39munit_normalize_all()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filter_word_embeddings:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\utils\\storage.py:15\u001B[0m, in \u001B[0;36mload_embeddings\u001B[1;34m(file_path)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_embeddings\u001B[39m(file_path):\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file_path \u001B[38;5;241m==\u001B[39m fasttext_embeddings_path:\n\u001B[1;32m---> 15\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mFastText\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_fasttext_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mwv\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m file_path \u001B[38;5;241m==\u001B[39m glove_embeddings_path:\n\u001B[0;32m     17\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m KeyedVectors\u001B[38;5;241m.\u001B[39mload_word2vec_format(file_path, no_header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\venv\\lib\\site-packages\\gensim\\utils.py:1522\u001B[0m, in \u001B[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_func1\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1517\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1518\u001B[0m         fmt\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, reason\u001B[38;5;241m=\u001B[39mreason),\n\u001B[0;32m   1519\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[0;32m   1520\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m   1521\u001B[0m     )\n\u001B[1;32m-> 1522\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\venv\\lib\\site-packages\\gensim\\models\\fasttext.py:580\u001B[0m, in \u001B[0;36mFastText.load_fasttext_format\u001B[1;34m(cls, model_file, encoding)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;129m@utils\u001B[39m\u001B[38;5;241m.\u001B[39mdeprecated(\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse load_facebook_vectors (to use pretrained embeddings) or load_facebook_model \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(to continue training with the loaded full model, more RAM) instead\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    572\u001B[0m )\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_fasttext_format\u001B[39m(\u001B[38;5;28mcls\u001B[39m, model_file, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    574\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Deprecated.\u001B[39;00m\n\u001B[0;32m    575\u001B[0m \n\u001B[0;32m    576\u001B[0m \u001B[38;5;124;03m    Use :func:`gensim.models.fasttext.load_facebook_model` or\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;124;03m    :func:`gensim.models.fasttext.load_facebook_vectors` instead.\u001B[39;00m\n\u001B[0;32m    578\u001B[0m \n\u001B[0;32m    579\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_facebook_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\venv\\lib\\site-packages\\gensim\\models\\fasttext.py:728\u001B[0m, in \u001B[0;36mload_facebook_model\u001B[1;34m(path, encoding)\u001B[0m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_facebook_model\u001B[39m(path, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    667\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load the model from Facebook's native fasttext `.bin` output file.\u001B[39;00m\n\u001B[0;32m    668\u001B[0m \n\u001B[0;32m    669\u001B[0m \u001B[38;5;124;03m    Notes\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    726\u001B[0m \n\u001B[0;32m    727\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 728\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_fasttext_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\venv\\lib\\site-packages\\gensim\\models\\fasttext.py:840\u001B[0m, in \u001B[0;36m_load_fasttext_format\u001B[1;34m(model_file, encoding, full_model)\u001B[0m\n\u001B[0;32m    826\u001B[0m model\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39mvocab_size\n\u001B[0;32m    828\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    829\u001B[0m \u001B[38;5;66;03m# This is here to fix https://github.com/RaRe-Technologies/gensim/pull/2373.\u001B[39;00m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    838\u001B[0m \u001B[38;5;66;03m# trimmed raw_vocab, so this change does not affect them.\u001B[39;00m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m--> 840\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mupdate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    842\u001B[0m model\u001B[38;5;241m.\u001B[39mnum_original_vectors \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39mvectors_ngrams\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    844\u001B[0m model\u001B[38;5;241m.\u001B[39mwv\u001B[38;5;241m.\u001B[39minit_post_load(m\u001B[38;5;241m.\u001B[39mvectors_ngrams)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Polysemy\\venv\\lib\\site-packages\\gensim\\models\\word2vec.py:693\u001B[0m, in \u001B[0;36mWord2Vec.prepare_vocab\u001B[1;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001B[0m\n\u001B[0;32m    691\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    692\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 693\u001B[0m     \u001B[43mnew_words\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m(word)\n\u001B[0;32m    694\u001B[0m     new_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m v\n\u001B[0;32m    695\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dry_run:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for embeddings_path, filename_prefix in zip(embeddings_paths, filename_prefixes):\n",
    "    for filter_word_embeddings in [False, True]:\n",
    "        \n",
    "        with open(f\"C:\\\\Users\\\\its_d\\\\Desktop\\\\{filename_prefix}_{'filtered' if filter_word_embeddings else 'original'}.txt\", 'w', encoding='utf-8') as file:\n",
    "            file.write(f'')\n",
    "                \n",
    "        embeddings = load_embeddings(embeddings_path)\n",
    "        embeddings.unit_normalize_all()\n",
    "        \n",
    "        if filter_word_embeddings:\n",
    "            embeddings = filter_embeddings(embeddings)\n",
    "        \n",
    "        query_words = load_csv(words_path)\n",
    "        keys = list(query_words['Word'])\n",
    "        \n",
    "        query_points = [embeddings[key] for key in keys]\n",
    "        \n",
    "        for point, key in zip(query_points, keys):\n",
    "            most_similar = embeddings.similar_by_vector(vector=point, topn=(k + 1))\n",
    "            most_similar_keys = [key for key, similarity in most_similar]\n",
    "            \n",
    "            with open(f\"C:\\\\Users\\\\its_d\\\\Desktop\\\\{filename_prefix}_{'filtered' if filter_word_embeddings else 'original'}.txt\", 'a', encoding='utf-8') as file:\n",
    "                file.write(f'{key}\\n')\n",
    "            \n",
    "            for neighborhood_size in range(10, 110, 10):\n",
    "                words = [key for key in most_similar_keys[1: (neighborhood_size + 1)]]\n",
    "                neighborhood = np.array([embeddings[key] for key in words])\n",
    "                \n",
    "                angles = dict()\n",
    "                for i in range(len(neighborhood)):\n",
    "                    for j in range(i + 1, len(neighborhood)):\n",
    "                        point1 = neighborhood[i]\n",
    "                        point2 = neighborhood[j]\n",
    "                        \n",
    "                        word1 = words[i]\n",
    "                        word2 = words[j]\n",
    "            \n",
    "                        cosine_similarity = np.dot(point1, point2) / (np.linalg.norm(point1) * np.linalg.norm(point2))\n",
    "                        angle_in_degrees = math.degrees(math.acos(cosine_similarity))\n",
    "                        angles[(word1, word2)] = angle_in_degrees\n",
    "    \n",
    "                pair, neighborhood_thickness = max(angles.items(), key=lambda item: item[1])\n",
    "                \n",
    "                with open(f\"C:\\\\Users\\\\its_d\\\\Desktop\\\\{filename_prefix}_{'filtered' if filter_word_embeddings else 'original'}.txt\", 'a', encoding='utf-8') as file:\n",
    "                    file.write(f'Neighborhood size = {neighborhood_size}: {neighborhood_thickness} {pair}\\n')\n",
    "            \n",
    "            with open(f\"C:\\\\Users\\\\its_d\\\\Desktop\\\\{filename_prefix}_{'filtered' if filter_word_embeddings else 'original'}.txt\", 'a', encoding='utf-8') as file:\n",
    "                file.write(f'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:06:03.326101Z",
     "start_time": "2023-12-11T19:02:10.804239900Z"
    }
   },
   "id": "dfd841743849b6f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7d21e90f86ec5b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
